{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "import pytesseract\n",
    "import fitz\n",
    "import io\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.image as mpimg \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition <br>\n",
    "<p> \n",
    "    Loop in the directory containing legal files and do the following elements <br>\n",
    "    <ul>\n",
    "        <li> Extract pictures from pdf files </li>\n",
    "        <li> Extract account number in corresponding page file </li>\n",
    "        <li> Associate account to pictures and save them in the folder </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matricule from file\n",
    "detector = MTCNN()\n",
    "def get_matricule(image):\n",
    "    # Convert pdf file into string\n",
    "    \n",
    "    found = None\n",
    "    \n",
    "    string = pytesseract.image_to_string(image).strip()\n",
    "\n",
    "    match_search = re.search('0\\d{10}', string)\n",
    "    if match_search:\n",
    "        found = match_search.group(0)\n",
    "        \n",
    "    return found\n",
    "\n",
    "#faces detector extraction funcfion\n",
    "def get_face_detector(image):\n",
    "    faces = detector.detect_faces(image)\n",
    "    \n",
    "    return faces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datas\\000010001095100221ETSKIKI.pdf\n",
      "datas\\000010001159105186TANKIOELISE.pdf\n",
      "datas\\000010001222105134KONGVOULATAPEREKONGVOULATAPERE.pdf\n",
      "datas\\000010002858105194KOUEKEM.pdf\n",
      "datas\\000010003072105139NDJIKEUEDMOND.pdf\n",
      "datas\\000010003072105139ndjikeuok.pdf\n",
      "datas\\000010003276105160CHAUNGEUJEAN.pdf\n",
      "datas\\000010003368105101FANKAMDAVID.pdf\n",
      "datas\\000010003939105204DOSSIEROUVERTURECOMPTE+DOSSIERSUPPLEMENTAIRE.pdf\n",
      "datas\\000010003957105106NGUEDJUITHERESE.pdf\n",
      "datas\\Couleur0899.pdf\n",
      "datas\\Couleur1053.pdf\n",
      "datas\\Couleur1055.pdf\n",
      "datas\\Couleur1126.pdf\n",
      "datas\\Couleur1127.pdf\n",
      "datas\\Couleur1129.pdf\n",
      "datas\\Couleur1130.pdf\n",
      "datas\\Couleur1138.pdf\n",
      "datas\\Couleur1187.pdf\n",
      "datas\\Couleur1195.pdf\n",
      "datas\\Couleur1316.pdf\n",
      "datas\\file.pdf\n"
     ]
    }
   ],
   "source": [
    "directory = 'datas'\n",
    "\n",
    "def func_cv_cascade(image):\n",
    "    \n",
    "    faceCascade = cv.CascadeClassifier(\"face_detector.xml\")\n",
    "    \n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "    faces = faceCascade.detectMultiScale2(gray,1.1,4, minSize=(145, 145))\n",
    "        \n",
    "    return faces\n",
    "\n",
    "#Loop through the files\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        path = os.path.join(subdir, file)\n",
    "        \n",
    "        # File reading\n",
    "        try:\n",
    "            file = fitz.open(path)\n",
    "            \n",
    "            print(path)\n",
    "        except Exception as e:\n",
    "            print(\"Error occured: {}\".format(e))\n",
    "            break\n",
    "        \n",
    "        # Process\n",
    "        \n",
    "        # Read images inside pdf\n",
    "        images = []\n",
    "        for page_index in range(len(file)):\n",
    "\n",
    "            #get page and images list\n",
    "            page = file[page_index]\n",
    "            images_list = page.getImageList()\n",
    "\n",
    "            images_number = len(images_list)\n",
    "\n",
    "            #print(\"Number of images: {}\".format(images_number))\n",
    "\n",
    "            if images_number != 0:\n",
    "\n",
    "                for image_index, img in enumerate(images_list, start=1):\n",
    "\n",
    "                    xref = img[0]\n",
    "                    \n",
    "                    # extract image bytes\n",
    "                    base_image = file.extractImage(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    # get image extension\n",
    "                    image_ext = base_image[\"ext\"]\n",
    "                    \n",
    "                    # Load PIL                    \n",
    "                    pil_image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "                    \n",
    "                    image = np.array(pil_image)\n",
    "                    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "                    \n",
    "#                     cv.imshow(\"im\", image)\n",
    "#                     cv.waitKey(0)\n",
    "\n",
    "                    faces = func_cv_cascade(image)\n",
    "                    #print(faces)\n",
    "                                        \n",
    "                    # Faces have been detected\n",
    "                    if len(faces[0]) is not 0:\n",
    "                        \n",
    "                        matricule = get_matricule(image)\n",
    "                        \n",
    "                        if matricule != None:\n",
    "                        \n",
    "                            for i, face in enumerate(faces):\n",
    "                                \n",
    "                                box = faces[0][0]\n",
    "\n",
    "                                x, y, h, w = box\n",
    "                                img = image[y:y + h, x:x + w]\n",
    "                                \n",
    "                                folder = directory + \"/\" + str(matricule) + \"/\"\n",
    "\n",
    "                                image_path = folder + str(image_index) + \"_\" + str(i) + \".\" + str(image_ext)\n",
    "                                \n",
    "                                \n",
    "                                Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "                                                                \n",
    "                                \n",
    "                                # img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "                                cv.imwrite(image_path, img)\n",
    "                                \n",
    "                                # Remove thses two lines in production\n",
    "                                doc_path = folder +  str(matricule) + \".pdf\"\n",
    "                                \n",
    "                                file.save(doc_path)\n",
    "                                \n",
    "                                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n",
      "Number of images: 1\n"
     ]
    }
   ],
   "source": [
    "# Read images inside pdf\n",
    "images = []\n",
    "for page_index in range(len(file)):\n",
    "    \n",
    "    #get page and images list\n",
    "    page = file[page_index]\n",
    "    images_list = page.getImageList()\n",
    "    \n",
    "    images_number = len(images_list)\n",
    "    \n",
    "    print(\"Number of images: {}\".format(images_number))\n",
    "    \n",
    "    if images_number != 0:\n",
    "        \n",
    "        for image_index, img in enumerate(images_list, start=1):\n",
    "            \n",
    "            xref = img[0]\n",
    "            \n",
    "            # extract image bytes\n",
    "            base_image = file.extractImage(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            \n",
    "            # get image extension\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            \n",
    "            # Load PIL\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            \n",
    "            image_path = \"datas/image\" + str(page_index + 1) + \"_\" + str(image_index) + \".\" + str(image_ext)\n",
    "            \n",
    "            image.save(image_path)\n",
    "            \n",
    "            image_path_merge = (image, image_path)\n",
    "            \n",
    "            images.append(image_path_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "<p>\n",
    "    This part of code is dedicated to model building, \n",
    "    we aim to build here the our classification model for face recognition.\n",
    "    The process is divided as follow:\n",
    "    <ul>\n",
    "        <li> Data augmentation: Using traditionnal method or Generation methods like Adversarial networks </li>\n",
    "        <li> Data preprocessing: To prepare the data in other to fit well model building process </li>\n",
    "        <li> Model building: We intend to build here a convolutionnal neural network if all conditions are met; <br>\n",
    "            Otherwise, we'll use a more suitable method </li>\n",
    "         <li> Model Evaluation: To evaluate our model accuracy </li>   \n",
    "    </ul>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 2048), (16, 2048))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = new_model.predict(X_train)\n",
    "X_test = new_model.predict(X_test)\n",
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00010951002',\n",
       " '00011591051',\n",
       " '00028581051',\n",
       " '00028581101',\n",
       " '00039391052',\n",
       " '00621451051',\n",
       " '04961881051',\n",
       " '06576441051',\n",
       " '06756641101',\n",
       " '06759901051',\n",
       " '06778321051',\n",
       " '06779911101',\n",
       " '06780511051',\n",
       " '06783231101',\n",
       " '06783611051',\n",
       " '06840591101',\n",
       " '06840691101']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert each face to his correspondent embedding\n",
    "def get_embedding(model, face):\n",
    "    \n",
    "    face = np.array(face).astype('float32')\n",
    "    \n",
    "    mean, std = face.mean(), face.std()\n",
    "    \n",
    "    face = (face - mean) / std\n",
    "    \n",
    "    # convert to model input\n",
    "    embed_face = np.expand_dims(face, axis=0)\n",
    "    \n",
    "    # get prediction\n",
    "    pred = model.predict(embed_face)\n",
    "    \n",
    "    return pred[0]\n",
    "\n",
    "\n",
    "#Loop through the files\n",
    "directory = \"imgs\"\n",
    "x_train = []\n",
    "y_train = []\n",
    "model_transfert  = load_model('keras-facenet/model/facenet_keras.h5')\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        path = os.path.join(subdir, file)\n",
    "        \n",
    "        # File reading\n",
    "        try:\n",
    "            #file = fitz.open(path)\n",
    "            \n",
    "            # get image\n",
    "            x = mpimg.imread(path)\n",
    "            x = cv.resize(x,(160,160))\n",
    "            \n",
    "            embedding = get_embedding(model_transfert, x)\n",
    "            x_train.append(embedding)\n",
    "            \n",
    "            # get account_number\n",
    "            path_split = path.split(\"\\\\\")\n",
    "            account_number = path_split[1]\n",
    "            y_train.append(account_number)\n",
    "                        \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error occured: {}\".format(e))\n",
    "x_train = np.array(x_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.03545853, 0.05663378, 0.05001278, 0.0596537 , 0.06225282,\n",
       "        0.0524389 , 0.05165692, 0.05923474, 0.05149576, 0.06021238,\n",
       "        0.0574472 , 0.05756227, 0.05428203, 0.06006576, 0.05730191,\n",
       "        0.06279877, 0.05632492, 0.05516683])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06279876903337908, '06784171051')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = new_model.predict_proba(new.reshape((1, -1)))\n",
    "max_prob = np.argmax(probas)\n",
    "probas[0][max_prob] , new_model.classes_[max_prob], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = y_train.reshape((-1))\n",
    "#y_test = y_test.reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train.shape[0]\n",
    "x_train = x_train.reshape((n, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = LogisticRegression(random_state=1)\n",
    "new_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.33295251e-01, 6.20720276e-03, 7.62768975e-03, 3.94905736e-03,\n",
       "        2.24489258e-03, 4.32721432e-03, 4.79450483e-03, 2.70579975e-03,\n",
       "        9.06593330e-03, 3.27900710e-03, 1.66995973e-03, 4.49848941e-03,\n",
       "        1.13506738e-03, 6.52959219e-04, 3.12386619e-03, 3.82473491e-03,\n",
       "        7.59837068e-03]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict_proba (x_train[0].reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00010951002', '00011591051', '00028581051', '00028581101',\n",
       "       '00039391052', '00621451051', '04961881051', '06576441051',\n",
       "       '06756641101', '06759901051', '06778321051', '06779911101',\n",
       "       '06780511051', '06783231101', '06783611051', '06840591101',\n",
       "       '06840691101'], dtype='<U11')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03604073, 0.05850242, 0.05624378, 0.05876766, 0.06370974,\n",
       "        0.05883437, 0.05840013, 0.0601526 , 0.05524242, 0.06264899,\n",
       "        0.06486085, 0.06052789, 0.06141757, 0.06658163, 0.06340428,\n",
       "        0.05870695, 0.05595799]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict_proba (x_train[0].reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = new_model.classes_\n",
    "probas = new_model.predict_proba (x_train[0].reshape((1,-1)))\n",
    "one = probas.reshape(-1).tolist()\n",
    "two = classes.tolist()\n",
    "preds = list(zip(one, two))\n",
    "preds.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'account_number': '00010951002', 'probability': 0.933295250725872},\n",
       " 1: {'account_number': '06756641101', 'probability': 0.009065933303239591},\n",
       " 2: {'account_number': '00028581051', 'probability': 0.0076276897479774395},\n",
       " 3: {'account_number': '06840691101', 'probability': 0.007598370679763024},\n",
       " 4: {'account_number': '00011591051', 'probability': 0.006207202756767783},\n",
       " 5: {'account_number': '04961881051', 'probability': 0.004794504829249769},\n",
       " 6: {'account_number': '06779911101', 'probability': 0.004498489414337839},\n",
       " 7: {'account_number': '00621451051', 'probability': 0.004327214322607562},\n",
       " 8: {'account_number': '00028581101', 'probability': 0.0039490573599957664},\n",
       " 9: {'account_number': '06840591101', 'probability': 0.003824734905385653},\n",
       " 10: {'account_number': '06759901051', 'probability': 0.0032790070997868585},\n",
       " 11: {'account_number': '06783611051', 'probability': 0.0031238661941713234},\n",
       " 12: {'account_number': '06576441051', 'probability': 0.0027057997517416247},\n",
       " 13: {'account_number': '00039391052', 'probability': 0.0022448925809427766},\n",
       " 14: {'account_number': '06778321051', 'probability': 0.0016699597311789838},\n",
       " 15: {'account_number': '06780511051', 'probability': 0.0011350673782390458},\n",
       " 16: {'account_number': '06783231101', 'probability': 0.0006529592187429487}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ index: {\"account_number\": tup[1], \"probability\": tup[0]} for index, tup in enumerate(preds) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = SVC(probability=True)\n",
    "new_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03604073, 0.05850242, 0.05624378, 0.05876766, 0.06370974,\n",
       "        0.05883437, 0.05840013, 0.0601526 , 0.05524242, 0.06264899,\n",
       "        0.06486085, 0.06052789, 0.06141757, 0.06658163, 0.06340428,\n",
       "        0.05870695, 0.05595799]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict_proba(x_train[0].reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=4, max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_train)\n",
    "accuracy_score(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = new_model.predict(x_train)\n",
    "accuracy_score(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['identity_model.sav']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(new_model, \"identity_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02348295, 0.        , ..., 0.05618392, 0.09274382,\n",
       "       0.53808534], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5424740016460419"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(X_train[0], X_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 7 from 5 for '{{node avg_pool/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 7, 7, 1], padding=\"VALID\", strides=[1, 7, 7, 1]](Placeholder)' with input shapes: [?,5,5,2048].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1852\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 7 from 5 for '{{node avg_pool/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 7, 7, 1], padding=\"VALID\", strides=[1, 7, 7, 1]](Placeholder)' with input shapes: [?,5,5,2048].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-06390b8e0d9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGGFace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resnet50'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'avg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_vggface\\vggface.py\u001b[0m in \u001b[0;36mVGGFace\u001b[1;34m(include_top, model, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m     95\u001b[0m                         \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpooling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                         \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                         classes=classes)\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'senet50'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_vggface\\models.py\u001b[0m in \u001b[0;36mRESNET50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet_identity_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2048\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'avg_pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 952\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[1;32m-> 1091\u001b[1;33m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    861\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         data_format=conv_utils.convert_data_format(self.data_format, 4))\n\u001b[0m\u001b[0;32m    301\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mavg_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[0;32m   4347\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4348\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4349\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mavg_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m     82\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m     83\u001b[0m         \u001b[1;34m\"AvgPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                    data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m     85\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    590\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3534\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3535\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3536\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3537\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3538\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m-> 2016\u001b[1;33m                                 control_input_ops, op_def)\n\u001b[0m\u001b[0;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1854\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1856\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1858\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 7 from 5 for '{{node avg_pool/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 7, 7, 1], padding=\"VALID\", strides=[1, 7, 7, 1]](Placeholder)' with input shapes: [?,5,5,2048]."
     ]
    }
   ],
   "source": [
    "new_model = VGGFace(model='resnet50', include_top=False, input_shape=(160, 160, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15929882, 0.3421023 , 0.26282205, 0.23577684],\n",
       "       [0.16880556, 0.24735219, 0.26879341, 0.31504885],\n",
       "       [0.18433299, 0.2422787 , 0.25757465, 0.31581367],\n",
       "       [0.22297237, 0.28735158, 0.25081702, 0.23885903],\n",
       "       [0.20723918, 0.24421581, 0.28531072, 0.26323429],\n",
       "       [0.27411606, 0.19240825, 0.25621964, 0.27725605],\n",
       "       [0.23844674, 0.21466563, 0.24831009, 0.29857754],\n",
       "       [0.26343751, 0.18766391, 0.30749227, 0.24140631],\n",
       "       [0.25502759, 0.2813136 , 0.19731278, 0.26634602],\n",
       "       [0.24187309, 0.29165293, 0.20555093, 0.26092305],\n",
       "       [0.22502309, 0.33470323, 0.15884981, 0.28142386],\n",
       "       [0.29195766, 0.26019563, 0.17974235, 0.26810436],\n",
       "       [0.25529127, 0.27663583, 0.24667334, 0.22139955],\n",
       "       [0.29220513, 0.34269004, 0.21594196, 0.14916287],\n",
       "       [0.24747249, 0.24516819, 0.297015  , 0.21034432],\n",
       "       [0.23623091, 0.28590656, 0.2710455 , 0.20681704]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_proba(X_train)\n",
    "#print(accuracy_score(y_train, pred))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_vggface'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-1b2f034814dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_vggface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvggface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGGFace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_vggface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_vggface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_vggface'"
     ]
    }
   ],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = Image.open(\"imgs/00010951002/1_0.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = image_test.resize((160,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 160, 160, 3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = np.array(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert each face to his correspondent embedding\n",
    "\n",
    "def get_embedding(model, face):\n",
    "    \n",
    "    face = np.array(face).astype('float32')\n",
    "    \n",
    "    mean, std = face.mean(), face.std()\n",
    "    \n",
    "    face = (face - mean) / std\n",
    "    \n",
    "    # convert to model input\n",
    "    embed_face = np.expand_dims(face, axis=0)\n",
    "    \n",
    "    # get prediction\n",
    "    pred = model.predict(embed_face)\n",
    "    \n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Convert to embeddings\n",
    "\n",
    "directory = \"new_im\"\n",
    "face_datas = {}\n",
    "\n",
    "for subdir, _, files in os.walk(\"new_im\"):\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        #Get matricule and image path\n",
    "        \n",
    "        image_path = os.path.join(subdir, file)\n",
    "        matricule = subdir.split(\"\\\\\")[1]\n",
    "        \n",
    "        im = cv.imread(image_path)\n",
    "        \n",
    "        face = get_face_detector(im)\n",
    "        \n",
    "        if len(face) == 0:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        box = get_face_detector(im)[0]['box']\n",
    "        \n",
    "        x, y, h, w = box\n",
    "\n",
    "        img = im[y-50:y+h+50, x-50:x+w]\n",
    "        \n",
    "        image = Image.fromarray(img).resize((160,160))\n",
    "\n",
    "        \n",
    "        #image = Image.open(image_path).resize((160,160))\n",
    "        \n",
    "        if matricule not in face_datas:\n",
    "            face_datas[matricule] = []\n",
    "            \n",
    "        face_datas[matricule].append(get_embedding(model, image))\n",
    "        \n",
    "print(len(face_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1', '10', '11', '4', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_datas.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min dist: 0.0\n",
      "Min dist: 10.924302101135254\n",
      "Min dist: 9.954599380493164\n",
      "Min dist: 10.33474349975586\n",
      "Min dist: 10.323163986206055\n",
      "Min dist: 6.508690357208252\n",
      "Min dist: 9.216507911682129\n",
      "Min dist: 10.051806449890137\n"
     ]
    }
   ],
   "source": [
    "min_treshold = 0.2\n",
    "\n",
    "for(name, encoded_image_name) in face_datas.items():\n",
    "      #distance between two embedding vector\n",
    "        dist = np.linalg.norm(face_datas['1'][0] - encoded_image_name)\n",
    "        print('Min dist: {}'.format(dist))\n",
    "        \n",
    "#         if(dist < min_dist):\n",
    "#             min_dist = dist\n",
    "#             identity = name\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flow() got an unexpected keyword argument 'preprocessing_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-0e023634e0b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mgenerate_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-102-0e023634e0b0>\u001b[0m in \u001b[0;36mgenerate_images\u001b[1;34m(img, directory, number)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     data_gen = data_gen.flow(image, batch_size=1, save_prefix=\"image\", save_format=\"jpg\", save_to_dir=directory,\n\u001b[1;32m---> 30\u001b[1;33m                             preprocessing_function=color_func)\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: flow() got an unexpected keyword argument 'preprocessing_function'"
     ]
    }
   ],
   "source": [
    "# Return only well colored images\n",
    "def color_func(image):\n",
    "    \n",
    "    image = np.array(image)\n",
    "    rbg = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(rgb)\n",
    "\n",
    "\n",
    "def generate_images(img, directory,  number=10,):\n",
    "    \n",
    "    #reshaping\n",
    "    image = img_to_array(img)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    #image gen\n",
    "    data_gen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=25,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\")\n",
    "    \n",
    "    # Generate and save to directory\n",
    "    \n",
    "    data_gen = data_gen.flow(image, batch_size=1, save_prefix=\"image\", save_format=\"jpg\", save_to_dir=directory)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(number):\n",
    "        next(data_gen)\n",
    "\n",
    "\n",
    "parent_direct = \"imgs\"\n",
    "\n",
    "for subdir, dirs, files in os.walk(parent_direct):\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        path = os.path.join(subdir, file)\n",
    "        \n",
    "        split = path.split(\"\\\\\")\n",
    "        \n",
    "        data_gen = ImageDataGenerator(\n",
    "        rotation_range=25,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        directory =  os.path.join(split[0], split[1], \"generates\")\n",
    "        \n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        img = cv.imread(path)\n",
    "        \n",
    "        generate_images(img, directory, 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"imgs\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-eb42ca6e4af3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights=constant.IMAGENET, include_top=False, input_tensor=Input(shape=(constant.IMG_WIDTH, constant.IMG_HEIGHT, 3)), pooling='max', classes=15)   \n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.get_layer('block5_pool').output\n",
    "# Stacking a new simple convolutional network on top of it\n",
    "x = Convolution2D(64, 3)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(constant.NUMBER_FULLY_CONNECTED, activation=constant.RELU_ACTIVATION_FUNCTION)(x)\n",
    "x = Dense(self.n_classes, activation=constant.SOFTMAX_ACTIVATION_FUNCTION)(x)\n",
    "\n",
    "self.vgg = Model(inputs=base_model.input, outputs=x)\n",
    "self.vgg.summary()\n",
    "\n",
    "def __init__(self, dataSet=None):\n",
    "   super().__init__(dataSet)\n",
    "   opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "   self.vgg.compile(loss=keras.losses.binary_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[constant.METRIC_ACCURACY])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
